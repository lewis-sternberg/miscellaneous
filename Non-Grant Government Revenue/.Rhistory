}
#setTxtProgressBar(pb, i)
#close(pb)
data.total.mics <- rbindlist(dataList, fill=T)
data.total.mics$datatype <- "mics"
long.data.mics <- rbindlist(longlist, fill=T)
long.data.mics$datatype <- "mics"
setwd(wd)
#save(data.total.mics, file="project_data/historical_micsmf.RData")
#save(long.data.mics, file="project_data/long_mics.RData")
save(data.total.mics, file="project_data/historical_micsmf_nexus.RData")
save(long.data.mics, file="project_data/long_mics_nexus.RData")
required.packages <- c("reshape2","ggplot2","data.table","WDI")
lapply(required.packages, require, character.only=T)
memory.limit(32000)
if(Sys.info()[["user"]]=="dan-w" | Sys.info()[["user"]]=="danw"){
wd <- "G:/My Drive/Work/GitHub/MICS_recode"
wd2 <- "G:/My Drive/Work/GitHub/MICS_recode/project_data/Merge datasets recode selected var"
} else if(Sys.info()[["user"]]=="lewis-s" | Sys.info()[["user"]]=="lewiss"){
wd <- "C:/git/MICS_recode/"
wd2 <- "C:/git/MICS_recode/project_data/Merge datasets recode selected var"
} else if(Sys.info()[["user"]]=="georgia-c" | Sys.info()[["user"]]=="georgiac"){
wd <- "C:/MICS_recode/"
wd2 <- "C:/MICS_recode/project_data/Merge datasets recode selected var"
}
setwd(wd)
##########################
vars_wanted <- c(
"sex"
,
"urban"
,
"p20"
,
"ext"
,
"u20"
,
"education_mother"
,
"education_father"
,
"education_max"
,
"education"
,
"birth.reg"
,
"ethnicity"
,
"region"
,
"subnational"
)
#########################
#################################################################################################
# Instead of rerunning the annual variable aggregation each time we want to do some analysis    #
# we check if our previous data aggregation already includes the variables we need. If it does  #
# then we just load it in. If it doesn't, then we do a new aggregation which takes a while...   #
#################################################################################################
#load("output/historical_dhs-mics.RData")
vars.todo <- vars_wanted
#if(!all(vars_wanted %in% names(dhs.mics))){
#vars.todo <- setdiff(vars_wanted, names(dhs.mics))
# print(paste("The following chosen variables are not currently aggregated:", paste(vars.todo, collapse=", ")))
#load("project_data/historical_micsmf.RData")
#load("project_data/historical_dhsmf.RData")
load("project_data/historical_micsmf_nexus.RData")
#load("project_data/historical_dhsmf_nexus.RData")
#setnames(data.total.mics, c("chweights_sum", "chweights_length", "chweights_sum.var"), c("value", "sample", "var"))
setnames(data.total.mics, c("weights_sum", "weights_length", "weights_sum.var"), c("value", "sample", "var"))
setnames(data.total.dhs, c("weights_sum", "weights_length", "weights_sum.var"), c("value", "sample", "var"))
#data.total <- rbind(data.total.dhs, data.total.mics, fill=T)
data.total <- data.total.mics
data.total <- data.total[iso3=="BGD"]
rm(data.total.dhs, data.total.mics)
data.total <- data.total[!is.nan(value)]
# if(!all(vars_wanted %in% names(data.total))){
#   missing.vars <- setdiff(vars_wanted, names(data.total))
#   print(paste("ERROR: The following chosen variables are not currently coded, so we cannot aggregate these:", paste(missing.vars, collapse=", ")))
#   if(all(setdiff(vars_wanted, missing.vars) %in% names(data.total))){
#     print("There are no new chosen variables available to aggregate.")
#     rm(data.total)
#     break
#   }
# }
#data.total <- data.total[!is.na(birth.reg)]
data.total[is.na(data.total)] <- -1
data.total[sex == 9]$sex <- -1 #Nigeria seems to have this
surveys <- unique(data.total[,c("iso3","survey_year","povcal_year","datatype")])
surveys$id <- seq(1,nrow(surveys))
var.cols <- names(data.total)[!(names(data.total) %in% c("iso3", "povcal_year", "survey_year", "datatype", "value", "sample", "variable", "var"))]
dums <- sapply(var.cols, function(x) unique(data.total[,..x]), USE.NAMES = F)
dat <- data.table(vars=var.cols, dums=dums)
# dums_dat <- function(var.cols){
#   temp <- dat[vars %in% var.cols]
#   dums.list <- setNames(temp$dums, temp$vars)
#   return(dums.list)
# }
# New method of generating a dummy grid. Instead of using every possible combination of variable outputs for each survey, we rather find every
# combination of variable outputs which exist across all surveys, and generate a grid for each survey from this combination.
#dummydata <- expand.grid(c(setNames(list(seq(1,nrow(surveys))), "id"), dums_dat(var.cols), setNames("registration", "variable")))
dummydata <- unique(data.total[,..var.cols])
dummydata <- cbind(dummydata[rep(seq_len(nrow(dummydata)), nrow(surveys)),], id=rep(1:nrow(surveys), each=nrow(dummydata)))
dummydata <- merge(surveys, dummydata, by="id")
dummydata$id <- NULL
data.total <- merge(dummydata, data.total, all.x=T)
rm(dummydata)
gc()
#data.total[is.na(value)]$value <- 0
#data.total[is.na(sample)]$sample <- 0
by.cols <- c("iso3", "povcal_year", var.cols)
agg.cols <- c(by.cols,"survey_year","datatype")
data.total <- data.total[, .(value=sum(value, na.rm=T), sample=sum(sample, na.rm=T), var=sum(var, na.rm=T)), by=agg.cols]
#Year weightings
data.total$diff <- abs(data.total$survey_year - data.total$povcal_year)
data.total[is.na(data.total$value)]$diff <- NA
data.total$diff.sign <- sign(data.total$survey_year - data.total$povcal_year)
pos.data.total <- data.total[diff.sign %in% c(0, 1)]
neg.data.total <- data.total[diff.sign %in% c(0,-1)]
neg.data.total <- neg.data.total[!(diff == 0)]
neg.data.total <- neg.data.total[!(do.call(paste0, neg.data.total[, ..by.cols]) %in% do.call(paste0, pos.data.total[diff == 0][, ..by.cols]))]
pos.data.total <- pos.data.total[pos.data.total[, .I[which.min(diff)], by = by.cols]$V1]
neg.data.total <- neg.data.total[neg.data.total[, .I[which.min(diff)], by = by.cols]$V1]
data.total <- rbind(pos.data.total, neg.data.total)
data.total[, year.weight := (sum(diff) - diff) / sum(diff), by = by.cols]
data.total$diff <- NULL
data.total$diff.sign <- NULL
data.total[year.weight == 0]$year.weight <- 1
data.total[is.nan(year.weight)]$year.weight <- 1
data.total[, value := value / sum(value, na.rm = T), by = .(iso3, povcal_year, survey_year, datatype)]
data.total.out <- data.total[, .(
value = sum(value * year.weight, na.rm = T) / sum(year.weight, na.rm = T),
sample = sum(sample, na.rm = T),
var = sum(year.weight ^ 2 * var, na.rm = T) / sum(year.weight ^ 2, na.rm = T),
survey_year = paste(survey_year, datatype, collapse = ";")
), by = by.cols]
pop <- as.data.table(WDI(indicator="SP.POP.TOTL", start=min(data.total.out$povcal_year), end=max(data.total.out$povcal_year), extra=T))
pop[iso2c=="KP"]$iso3c <- "PRK"
pop[iso2c=="MD"]$iso3c <- "MKD"
pop[iso2c=="SZ"]$iso3c <- "SWZ"
pop <- setnames(pop[,c("iso3c","year","SP.POP.TOTL")],c("iso3","povcal_year","ReqYearPopulation"))
#Population weightings
data.total.out <- merge(data.total.out, pop, by=c("iso3","povcal_year"), all.x=T)
data.total.out$value <- data.total.out$value * data.total.out$ReqYearPopulation
data.total.out$var <- data.total.out$var * data.total.out$ReqYearPopulation^2
#Rename variable results to plain English
data.total.out <- cbind(data.total.out[,!(..var.cols)], data.table(sapply(data.total.out[,..var.cols], as.character)))
data.total.out[ext=="1"]$ext <- "Extreme poor"
data.total.out[ext=="0"]$ext <- "Not extreme poor"
data.total.out[ext=="-1"]$ext <- "(Ext) No data"
data.total.out[p20=="1"]$p20 <- "P20"
data.total.out[p20=="0"]$p20 <- "Not P20"
data.total.out[p20=="-1"]$p20 <- "(P20) No data"
data.total.out[u20=="1"]$u20 <- "U20"
data.total.out[u20=="0"]$u20 <- "Not U20"
data.total.out[u20=="-1"]$u20 <- "(U20) No data"
data.total.out[sex=="1"]$sex <- "Male"
data.total.out[sex=="2"]$sex <- "Female"
data.total.out[sex=="-1"]$sex <- "(Sex) No data"
data.total.out[urban=="1"]$urban <- "Urban"
data.total.out[urban=="0"]$urban <- "Rural"
data.total.out[urban=="-1"]$urban <- "(Area) No data"
data.total.out[birth.reg=="1"]$birth.reg <- "Registered"
data.total.out[birth.reg=="0"]$birth.reg <- "Not registered"
data.total.out[education_max=="1"]$education_max <- "Max: Less than primary"
data.total.out[education_max=="2"]$education_max <- "Max: Primary"
data.total.out[education_max=="3"]$education_max <- "Max: Secondary"
data.total.out[education_max=="4"]$education_max <- "Max: Teritary"
data.total.out[education_max=="-1"]$education_max <- "(Education_max) No data"
data.total.out[education_mother=="1"]$education_mother <- "Mother: Less than primary"
data.total.out[education_mother=="2"]$education_mother <- "Mother: Primary"
data.total.out[education_mother=="3"]$education_mother <- "Mother: Secondary"
data.total.out[education_mother=="4"]$education_mother <- "Mother: Teritary"
data.total.out[education_mother=="-1"]$education_mother <- "(Education_mother) No data"
data.total.out[education_father=="1"]$education_father <- "Father: Less than primary"
data.total.out[education_father=="2"]$education_father <- "Father: Primary"
data.total.out[education_father=="3"]$education_father <- "Father: Secondary"
data.total.out[education_father=="4"]$education_father <- "Father: Teritary"
data.total.out[education_father=="-1"]$education_father <- "(Education_father) No data"
data.total.out[education=="1"]$education <- "Education: Less than primary"
data.total.out[education=="2"]$education <- "Education: Primary"
data.total.out[education=="3"]$education <- "Education: Secondary"
data.total.out[education=="4"]$education <- "Education: Teritary"
data.total.out[education=="-1"]$education <- "(Education) No data"
data.total.out[ethnicity== "-1"]$ethnicity <- "(ethnicity) No data"
data.total.out[ethnicity== "1"&iso3=="BEN"]$ethnicity <-"Adja et apparentés"
data.total.out[ethnicity== "2"&iso3=="BEN"]$ethnicity <- "Bariba et apparentés"
data.total.out[ethnicity== "3"&iso3=="BEN"]$ethnicity <- "Dendi et apparentés"
data.total.out[ethnicity== "4"&iso3=="BEN"]$ethnicity <- "Fon et apparentés"
data.total.out[ethnicity== "5"&iso3=="BEN"]$ethnicity <- "Yoa & lokpa apparentés"
data.total.out[ethnicity== "6"&iso3=="BEN"]$ethnicity <- "Betamaribe et apparentés"
data.total.out[ethnicity== "7"&iso3=="BEN"]$ethnicity <- "Peulh et apparentés"
data.total.out[ethnicity== "8"&iso3=="BEN"]$ethnicity <- "Yoruba et apparentés"
data.total.out[ethnicity== "9"&iso3=="BEN"]$ethnicity <- "Autres béninois"
data.total.out[ethnicity== "10"&iso3=="BEN"]$ethnicity <- "missing"
data.total.out[ethnicity== "1"&iso3=="BGD"]$ethnicity <- "Bangali"
data.total.out[ethnicity== "9"&iso3=="BGD"]$ethnicity <-"missing"
data.total.out[ethnicity!="Bangali"&ethnicity!="missing"&iso3=="BGD"]$ethnicity <-"other"
data.total.out[ethnicity== "1"&iso3=="NGA"]$ethnicity <- "Hausa"
data.total.out[ethnicity== "2"&iso3=="NGA"]$ethnicity <- "Igbo"
data.total.out[ethnicity== "3"&iso3=="NGA"]$ethnicity <- "Yoruba"
data.total.out[ethnicity== "4"&iso3=="NGA"]$ethnicity <- "other"
data.total.out[ethnicity== "9"&iso3=="NGA"]$ethnicity <- "missing"
data.total.out[subnational== "1"&iso3=="CMR"]$subnational <- "Adamawa"
data.total.out[subnational== "2"&iso3=="CMR"]$subnational <- "Central Cameroon"
data.total.out[subnational== "3"&iso3=="CMR"]$subnational <- "East Cameroon"
data.total.out[subnational== "4"&iso3=="CMR"]$subnational <- "Far North Cameroon"
data.total.out[subnational== "5"&iso3=="CMR"]$subnational <- "Littoral Cameroon"
data.total.out[subnational== "6"&iso3=="CMR"]$subnational <- "North Cameroon"
data.total.out[subnational== "7"&iso3=="CMR"]$subnational <- "Northwest Cameroon"
data.total.out[subnational== "8"&iso3=="CMR"]$subnational <- "South Cameroon"
data.total.out[subnational== "9"&iso3=="CMR"]$subnational <- "Southwest Cameroon"
data.total.out[subnational== "10"&iso3=="CMR"]$subnational <- "West Cameroon"
data.total.out[subnational== "1"&iso3=="BGD"]$subnational <- "Barisal"
data.total.out[subnational== "2"&iso3=="BGD"]$subnational <- "Chittagong"
data.total.out[subnational== "3"&iso3=="BGD"]$subnational <- "Dhaka"
data.total.out[subnational== "4"&iso3=="BGD"]$subnational <- "Khulna"
data.total.out[subnational== "5"&iso3=="BGD"]$subnational <- "Rajshahi"
data.total.out[subnational== "6"&iso3=="BGD"]$subnational <- "Rangpur"
data.total.out[subnational== "7"&iso3=="BGD"]$subnational <- "Sylhet"
data.total.out[subnational== "8"&iso3=="BGD"]$subnational <- "Mymenshing"
data.total.out[subnational== "0"&iso3=="UGA"]$subnational <- "Kampala"
data.total.out[subnational== "1"&iso3=="UGA"]$subnational <- "South Buganda"
data.total.out[subnational== "2"&iso3=="UGA"]$subnational <- "North Buganda"
data.total.out[subnational== "3"&iso3=="UGA"]$subnational <- "Busoga"
data.total.out[subnational== "4"&iso3=="UGA"]$subnational <- "Bukedi"
data.total.out[subnational== "5"&iso3=="UGA"]$subnational <- "Bugisu"
data.total.out[subnational== "6"&iso3=="UGA"]$subnational <- "Teso"
data.total.out[subnational== "7"&iso3=="UGA"]$subnational <- "Karamoja"
data.total.out[subnational== "8"&iso3=="UGA"]$subnational <- "Lango"
data.total.out[subnational== "9"&iso3=="UGA"]$subnational <- "Acholi"
data.total.out[subnational== "10"&iso3=="UGA"]$subnational <- "West Nile"
data.total.out[subnational== "11"&iso3=="UGA"]$subnational <- "Bunyoro"
data.total.out[subnational== "12"&iso3=="UGA"]$subnational <- "Tooro"
data.total.out[subnational== "13"&iso3=="UGA"]$subnational <- "Ankole"
data.total.out[subnational== "14"&iso3=="UGA"]$subnational <- "Kigezi"
dhs.mics <- data.total.out
regions <- read.csv("project_data/regions.csv")
names(regions)[1] <-"iso3"
library(dplyr)
dhs.mics <- left_join(dhs.mics,regions, by="iso3")
setDT(dhs.mics)
dhs.mics[dhs.mics$CountryName=="Kosovo"]$region <- "Europe"
dhs.mics[region!="Africa",africa:="rest"]
dhs.mics[region=="Africa",africa:="africa"]
save(dhs.mics,file="output/historical_dhs-mics_nexus.RData")
rm(list=ls()[ls() != "dhs.mics"])
#}
list.of.packages <- c("data.table","rJava","scrapeR","tabulizer","miniUI","jsonlite")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only=T)
# Watch the output of this lapply. If you see any that return `FALSE` that means
# At least one package failed to install. It will most likely be tabulizer, which requires
# you install and set JAVA_HOME. See https://docs.oracle.com/cd/E19182-01/820-7851/inst_cli_jdk_javahome_t/
# for further instructions.
# Edit this working directory before trying to load these files
setwd("C:/git/di_r_reference-master")
tab_col_names = c("sprog","desc","recurrent","domestic","external","total")
# We use `list.files` to grab a list of all the pdf file names in the ghana_pdfs folder.
pdfs = list.files(path="data/ghana_pdfs",pattern="*.pdf",full.names=TRUE)
# We set up an empty list to capture data as we loop through the pdfs.
dat.list = list()
# Now Tabulizer will try and guess where the data you want to extract is.
# If your data is a bit messy, you will need to use the `locate_areas` function first
# To find the boundaries of the columns. Try using the command below to get the `right`
# value from the `sprog` and `description` columns
locate_areas(pdfs[1])
setwd("C:/git/miscellaneous/Non-Grant Government Revenue")
pdfs = list.files(path="data",pattern="*.pdf",full.names=TRUE)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs = list.files(path="data",pattern="*.pdf",full.names=TRUE)
pdfs = list.files(path="data/",pattern="*.pdf",full.names=TRUE)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs = list.files(path="data/",pattern="*.pdf",full.names=TRUE)
?list.files
pdfs <- list.files(path="data",full.names=TRUE)
locate_areas(pdfs[1])
pdf <- pdfs[1]
bname = basename(pdf)
bname
country <- substr(bname,1,nchar(bname)-15)
country
country <- substr(bname,1,nchar(bname)-25)
country
country <- substr(bname,1,nchar(bname)-30)
country <- substr(bname,1,nchar(bname)-35)
country <- substr(bname,1,nchar(bname)-36)
length(country)
count(country)
str_length(country)
nchar(country)
source <- substr(bname,nchar(country+1),nchar(bname))
source <- substr(bname,nchar(country)+1,nchar(bname))
source <- substr(bname,nchar(country)+3,nchar(bname))
source <- substr(bname,nchar(country)+4,nchar(bname))
source <- gsub("-","/",source)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
locate_areas(pdfs[1])
?extract_tables
tabs <- extract_tables(pdf)
tabs
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs)
tab_df = rbindlist(tab_dfs,fill=T)
View(tab_df)
locate_areas(pdfs[1])
pdfs = list.files(path="data/ghana_pdfs",pattern="*.pdf",full.names=TRUE)
# We set up an empty list to capture data as we loop through the pdfs.
dat.list = list()
# Now Tabulizer will try and guess where the data you want to extract is.
# If your data is a bit messy, you will need to use the `locate_areas` function first
# To find the boundaries of the columns. Try using the command below to get the `right`
# value from the `sprog` and `description` columns
locate_areas(pdfs[1])
setwd("C:/git/di_r_reference-master")
# First, we're going to extract tables from a series of 30 PDF files
# If you look in the "data" folder in this repo, you can see the pdfs in the "ghana_pdfs" folder.
# Go ahead and open one up to follow along with.
# These are the columns we want to extract
tab_col_names = c("sprog","desc","recurrent","domestic","external","total")
# We use `list.files` to grab a list of all the pdf file names in the ghana_pdfs folder.
pdfs = list.files(path="data/ghana_pdfs",pattern="*.pdf",full.names=TRUE)
# We set up an empty list to capture data as we loop through the pdfs.
dat.list = list()
# Now Tabulizer will try and guess where the data you want to extract is.
# If your data is a bit messy, you will need to use the `locate_areas` function first
# To find the boundaries of the columns. Try using the command below to get the `right`
# value from the `sprog` and `description` columns
locate_areas(pdfs[1])
tabs <- extract_tables(pdf,method="decide")
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs <- list.files(path="data",full.names=TRUE)
locate_areas(pdfs[1])
pdf <- pdfs[1]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf,method="decide")
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
View(tab_dfs)
tabs <- extract_tables(pdf,method="decide")
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
View(tab_df)
extract_tables
?extract_tables
tabs <- extract_tables(pdf,
columns=list(
locate_areas(pdf),locate_areas(pdf)
),
guess=F)
tabs <- extract_tables(pdf,
columns=list(
c(locate_areas(pdf)),c(locate_areas(pdf))
),
guess=F)
?extract_tables
tabs <- extract_tables(pdf,
columns=list(,
guess=F)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs <- list.files(path="data",full.names=TRUE)
pdf <- pdfs[1]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
View(tab_df)
setwd("C:/git/di_r_reference-master")
# First, we're going to extract tables from a series of 30 PDF files
# If you look in the "data" folder in this repo, you can see the pdfs in the "ghana_pdfs" folder.
# Go ahead and open one up to follow along with.
# These are the columns we want to extract
tab_col_names = c("sprog","desc","recurrent","domestic","external","total")
# We use `list.files` to grab a list of all the pdf file names in the ghana_pdfs folder.
pdfs = list.files(path="data/ghana_pdfs",pattern="*.pdf",full.names=TRUE)
# We set up an empty list to capture data as we loop through the pdfs.
dat.list = list()
# Now Tabulizer will try and guess where the data you want to extract is.
# If your data is a bit messy, you will need to use the `locate_areas` function first
# To find the boundaries of the columns. Try using the command below to get the `right`
# value from the `sprog` and `description` columns
locate_areas(pdfs[1])
# This is the process I used to get the boundaries between columns in the `columns` argument below.
# Loop through the pdfs
for(i in 1:length(pdfs)){
pdf = pdfs[i]
# Extract the district name from the pdf filename
bname = basename(pdf)
district = substr(bname,1,nchar(bname)-15)
# Print out the district name to track our progress
message(district)
# Extract the tables
tabs = extract_tables(
pdf
,columns=list(c(95.7,395.6,482,576.5,667,756.6))
,guess=F
)
# Turn the extract into a data frame
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs)
# In this case, we're looking for those codes specifically, so we throw out the rest
relevant_rows = subset(tab_df,X1 %in% c("D101","D102","D201","D202","D203"))
# Set nice column names
names(relevant_rows) = tab_col_names
# Reshape and remove commas from numeric data
rel_rows_long = melt(relevant_rows,id.vars=c("sprog","desc"))
rel_rows_long$value = as.numeric(gsub(",","",rel_rows_long$value))
# Attach the district name to the data (since it's all going to be lumped together later)
rel_rows_long$district = district
# Add it to the list, repeat the loop until we get to the last pdf
dat.list[[district]] = rel_rows_long
}
i=1
pdf = pdfs[i]
# Extract the district name from the pdf filename
bname = basename(pdf)
district = substr(bname,1,nchar(bname)-15)
# Print out the district name to track our progress
message(district)
# Extract the tables
tabs = extract_tables(
pdf
,columns=list(c(95.7,395.6,482,576.5,667,756.6))
,guess=F
)
# Turn the extract into a data frame
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs)
View(tab_df)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs <- list.files(path="data",full.names=TRUE)
pdf <- pdfs[1]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
View(tab_df)
setDT(tab_df)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs <- list.files(path="data",full.names=TRUE)
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
View(tab_df)
pdfs <- list.files(path="data",full.names=TRUE)
pdf <- pdfs[2]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
tabs <- extract_tables(pdf)
pdf <- pdfs[1]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs <- list.files(path="data",full.names=TRUE)
pdf <- pdfs[1]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
setwd("C:/git/miscellaneous/Non-Grant Government Revenue/")
pdfs <- list.files(path="data",full.names=TRUE)
pdf <- pdfs[2]
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
locate_areas(pdf)
bname <- basename(pdf)
country <- substr(bname,1,nchar(bname)-36)
source <- substr(bname,nchar(country)+4,nchar(bname)-4)
source <- gsub("-","/",source)
tabs <- extract_tables(pdf)
tab_dfs = lapply(tabs,data.frame)
tab_df = rbindlist(tab_dfs,fill=T)
